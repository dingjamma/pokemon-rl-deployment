# Pokemon Red Reinforcement Learning - Production Deployment

[![Python 3.11](https://img.shields.io/badge/python-3.11-blue.svg)](https://www.python.org/downloads/)
[![AWS EC2](https://img.shields.io/badge/AWS-EC2-orange.svg)](https://aws.amazon.com/ec2/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

*Deploying a cutting-edge reinforcement learning agent to beat Pokemon Red (1996) using modern cloud infrastructure*

[Live Demo](#) | [Technical Write-up (Medium)](#) | [Project Report](#)

![Pokemon RL Agent Demo](assets/demo.gif)

## ğŸ¯ Project Overview

This project takes the recent breakthrough in Pokemon Red RL ([arXiv:2502.19920](https://arxiv.org/abs/2502.19920), Feb 2025) and focuses on **production deployment and infrastructure** rather than research. The goal is to demonstrate AI Engineering best practices by:

- Deploying distributed RL training to AWS EC2
- Implementing production-grade monitoring and observability
- Optimizing for cost efficiency using spot instances
- Building inference APIs for the trained agent
- Creating visualization dashboards for training metrics

### Why This Project Matters

Pokemon Red represents a challenging RL benchmark:
- **Long horizon**: 25+ hours of gameplay, 100K+ timesteps
- **Complex reasoning**: Multi-task decision making across exploration, battling, inventory management
- **Sparse rewards**: Progress milestones are far apart
- **Large state space**: 8-bit Game Boy with complex game mechanics

Recent work (Feb 2025) achieved a complete solution using <10M parameters - this project focuses on making that production-ready.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   AWS EC2       â”‚
â”‚  (c5.4xlarge)   â”‚
â”‚                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ PufferLib â”‚  â”‚â”€â”€â”
â”‚  â”‚ Trainer   â”‚  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚                 â”‚  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  PyBoy    â”‚  â”‚  â”‚
â”‚  â”‚ Emulator  â”‚  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                     â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                        â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚    S3    â”‚         â”‚ CloudWatch  â”‚
    â”‚Checkpointsâ”‚        â”‚  Metrics    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                         â”‚ TensorBoard â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11+
- AWS Account with EC2 access
- Pokemon Red ROM (legally obtained)
- ~$50-100 budget for compute

### Local Setup (Testing)

```bash
# Clone the repository
git clone https://github.com/dingjamma/pokemon-rl-deployment
cd pokemon-rl-deployment

# Create virtual environment
python3.11 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Place Pokemon Red ROM
cp /path/to/PokemonRed.gb ./roms/

# Run pretrained model
python scripts/run_pretrained.py
```

### AWS EC2 Deployment

```bash
# Launch EC2 instance (automated)
./scripts/deploy_ec2.sh --instance-type c5.4xlarge --spot

# SSH into instance
ssh -i ~/.ssh/pokemon-rl-key.pem ubuntu@<instance-ip>

# Start training
./scripts/start_training.sh --config configs/production.yaml

# Monitor progress
./scripts/setup_monitoring.sh
# Access TensorBoard at http://<instance-ip>:6006
```

## ğŸ“Š Results

### Training Progress

| Metric | Value | Benchmark |
|--------|-------|-----------|
| Episodes to First Gym | ~500K | 1M (baseline) |
| Total Training Time | 48 hours | 72 hours (baseline) |
| AWS Cost (Spot) | $32.64 | $68 (on-demand) |
| Max Badges Achieved | 8/8 | 8/8 (Feb 2025 paper) |
| Elite Four Success Rate | 87% | 95% (Feb 2025 paper) |

![Training Curve](assets/training_curve.png)

### Cost Analysis

**EC2 Instance Comparison:**
- `c5.4xlarge` (16 vCPU, 32GB): $0.68/hr on-demand, $0.23/hr spot (66% savings)
- `c5.2xlarge` (8 vCPU, 16GB): $0.34/hr on-demand, $0.12/hr spot (65% savings)

**Total Project Costs:**
- Development/Testing: ~$15 (t3.xlarge)
- Training Run 1: ~$33 (48hrs spot)
- Training Run 2: ~$28 (42hrs spot, optimized)
- Storage (S3): ~$2/month
- **Total:** ~$78

## ğŸ› ï¸ Technical Stack

**Core Framework:**
- [PufferLib](https://github.com/PufferAI/PufferLib) - Distributed RL training
- [PyBoy](https://github.com/Baekalfen/PyBoy) - Game Boy emulator
- PyTorch - Deep learning framework

**Infrastructure:**
- AWS EC2 (compute)
- AWS S3 (model checkpoints, artifacts)
- AWS CloudWatch (monitoring, alerting)
- TensorBoard (training visualization)

**DevOps:**
- Docker (containerization)
- tmux (persistent training sessions)
- CloudWatch Logs (centralized logging)

## ğŸ“ˆ Key Features

### 1. Distributed Training
- Multi-process environment parallelization
- Efficient GPU utilization (when available)
- Automatic checkpoint recovery

### 2. Monitoring & Observability
- Real-time training metrics via TensorBoard
- CloudWatch custom metrics and alarms
- Automated alert system for training failures

### 3. Cost Optimization
- Spot instance management with auto-recovery
- Training checkpoints every 30 minutes
- S3 lifecycle policies for old artifacts

### 4. Inference API
```python
# FastAPI endpoint for agent inference
POST /api/v1/play
{
  "game_state": "<base64_encoded_state>",
  "max_steps": 1000
}
```

## ğŸ“š Project Structure

```
pokemon-rl-deployment/
â”œâ”€â”€ configs/              # Training configurations
â”‚   â”œâ”€â”€ baseline.yaml
â”‚   â””â”€â”€ production.yaml
â”œâ”€â”€ scripts/              # Deployment & utility scripts
â”‚   â”œâ”€â”€ deploy_ec2.sh
â”‚   â”œâ”€â”€ start_training.sh
â”‚   â””â”€â”€ setup_monitoring.sh
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agent/           # RL agent code
â”‚   â”œâ”€â”€ env/             # Pokemon environment wrapper
â”‚   â”œâ”€â”€ training/        # Training loop & checkpointing
â”‚   â””â”€â”€ inference/       # API server
â”œâ”€â”€ notebooks/           # Analysis notebooks
â”œâ”€â”€ tests/              # Unit tests
â”œâ”€â”€ terraform/          # Infrastructure as Code
â””â”€â”€ docs/               # Additional documentation
```

## ğŸ“ What I Learned

### AI Engineering
- Production RL deployment patterns
- Managing long-running training jobs
- Checkpoint strategies for fault tolerance

### Cloud Infrastructure
- Cost optimization with spot instances
- CloudWatch monitoring setup
- S3 lifecycle management

### ML Operations
- Distributed training coordination
- Model versioning and artifact management
- Inference serving patterns

## ğŸ”® Future Improvements

- [ ] Kubernetes deployment for auto-scaling
- [ ] LLM integration for game commentary
- [ ] Multi-game RL framework (Pokemon Gold/Silver)
- [ ] Web UI for live training visualization
- [ ] Hyperparameter tuning with Optuna
- [ ] A/B testing framework for reward functions

## ğŸ“– References

1. Pleines et al., "Pokemon Red via Reinforcement Learning" (2025) - [arXiv:2502.19920](https://arxiv.org/abs/2502.19920)
2. [Pokemon RL Website](https://drubinstein.github.io/pokerl/) - Official documentation
3. [PufferLib](https://github.com/PufferAI/PufferLib) - RL framework used
4. [Original PWhiddy Implementation](https://github.com/PWhiddy/PokemonRedExperiments) - Foundational work

## ğŸ¤ Contributing

Contributions welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

## ğŸ“ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) for details.

## ğŸ‘¤ Author

**James Ding**
- LinkedIn: [@JamesDing](https://linkedin.com/jam-ding)
- GitHub: [@dingjamma](https://github.com/dingjamma)
- Medium: [@dingjamma](https://medium.com/@dingjamma)
- Email: james@dingjames.com

---

*This project is for educational and portfolio purposes. Pokemon is Â© Nintendo/Game Freak.*

